1401.6508v1 [cs.NI] 25 Jan 2014

arXiv

The Effect of Network and Infrastructural Variables
on SPDY’s Performance

Yehia Elkhatib
The School of Computing & Communications, Lancaster University
y.elkhatib@lancaster.ac.uk

Gareth Tyson
EECS, Queen Mary, University of London
gareth.tyson@eecs.qmul.ac.uk

Michael Welz]
Department of Informatics, University of Oslo
michawe@ifi.uio.no

June 4, 2018

Abstract

HTTP is a successful Internet technology on top of which a lot of
he web resides. However, limitations with its current specification,
ie. HTTP/1.1, have encouraged some to look for the next generation
of HTTP. In SPDY, Google has come up with such a proposal that
has growing community acceptance, especially after being adopted by
he IETF HTTPbis-WG as the basis for HTTP/2.0. SPDY has the
otential to greatly improve web experience with little deployment
overhead. However, we still lack an understanding of its true poten-
ial in different environments. This paper seeks to resolve these issues,
offering a comprehensive evaluation of SPDY’s performance using ex-
ensive experiments. We identify the impact of network characteristics
and website infrastructure on SPDY’s potential page loading benefits,
finding that these factors are decisive for SPDY and its optimal deploy-
ment strategy. Through this, we feed into the wider debate regarding
HTTP/2.0, exploring the key aspects that impact the performance of
his future protocol.

1 Introduction

Web pages are constantly increasing in complexity and size. The HTTP
Archive reports that the global average web page size has surpassed 1MB
in April 2012 [I]. By the start of July 2013, visiting one of the top 1000
sites incurs, on average, 1246kB of web page resources over 100 separate


requests [I]. Such growth has been fueled by the emergence of advancec
web-based services (Web 2.0, SaaS cloud services, etc.), enhanced clien
device capabilities (JavaScript browser runtimes [24], display), and increasec
downlink speeds [4]. This growing complexity, however, can dramatically
slow down page retrieval. Unfortunately, this has negative consequences
[26], and very real ones in the case of commercial websites. It has been
found that most users cannot tolerate in excess of 2 seconds of page loac
delay 21], and that increments of just 100ms on shopping websites can
decrease sales by 1% [19]. The converse is similarly true: decreasing delay
can have a powerful enhancing effect, with Google claiming to have increasec
ad revenue by 20% through cutting 500ms from load times. To mitigate page
load times, various extensions to HTTP have been proposed. However, in
practice, little progress has been made, with many web servers, proxies anc
browsers being slow to adopt these new tweaks (e.g. pipelining [I]]).

In light of these observations, some have proposed developing a new
web protocol. Such efforts include Microsoft’s Speed+Mobility anc
HTML5 Websockets; most prominent, however, is Google’s SPDY [3]. This
has already begun to see deployment by prominent organisations such as
Google, Twitter, Akamai and Facebook, whilst also being adopted as the
base for HTTP/2.0 by the HTTPbis Working Group. Despite this, we stil
possess a limited understaning of its behaviour, overheads and performance:
does it offer a fundamental improvement or just further tweaking?

In an attempt to answer the above question, a small number of early
stage studies have explored the topic. They offer a range of results, with
some claiming significant gains and (curiously) others claiming rather neg-
ative results. This report seeks to resolve these issues, by analysing the
circumstances under which SPDY can improve page load times, and the
ones where the opposite is true.

To achieve this, we perform a large-scale evaluation of SPDY using an
emulated testbed. Based on NPN negotiation handshakes, we found out that
the number of top 10,000 Alexa sites adopting SPDY was 208 on October
14* 2012, rising to 271 on April 23"¢ 2013. Using some of these websites, we
execute a large number of probes to measure the performance of SPDY in
the wild. Confirming our suspicions, we find highly variable results between
different websites and samples: SPDY has the potential to both benefit
and damage page load times. Motivated by this, we perform a large body of
controlled experiments in our local testbed to understand the reasons behind
these performance variations. We identify the website types and network
characteristics that SPDY thrives under, as well as how these benefits vary
based on provider-side infrastructural decisions. To our knowledge, this is
the first effort to offer such insights.

The rest of the report is organized as follows. Section [2] provides back-
ground and highlights related work. Section [3] describes our measurement
toolkit and environments. Section[4]presents the results of comparing SPDY



to HTTPS on live websites. We then use an emulated network testbed in
order to dissect the factors affecting SPDY performance, namely network
characteristics (section 5) and infrastructure setup (section [6). Section
concludes and discusses future work.

2 Background and Related Work
2.1 SPDY

SPDY is an application-layer web protocol that reuses HTTP’s semantics
[11]. As such, it retains all features including cookies, ETags and Content-
Encoding negotiations. SPDY only replaces the manner in which data is
written to the network. The purpose of this is to reduce page load time. It
does this by introducing the following mechanisms:

e Multiplexing: A framing layer multiplexes streams over a single con-
nection, removing the need to establish separate TCP connections for
transferring different page resources.

e Compression: All header data is compressed to reduce the overheads
of multiple related requests.

e Universal encryption: SPDY is negotiated over SSL/TLS and thus
operates exclusively over a secure channel in order to address the in-
creasing amounts of traffic sent over insecure paths (e.g. public WiFi).

e Server Push/Hint: Servers could proactively push resources to clients
(e.g. scripts and images that will be required). Alternatively, SPDY
can send hints advising clients to pre-fetch content.

e Content prioritization: A client can specify the preferred order in
which resources should be transferred.

SPDY consists of two components. The first provides framing of data,
thereby allowing things like compression and multiplexing. The framing
layer works on top of secure (SSL/TLS) persistent TCP connections that
are kept alive as long as the corresponding web pages are open. Clients
and servers exchange control and data frames, both of which contain an 8
bytes header. Control frames are used for carrying connection management
signals and configuration options, while data frames carry HTTP requests
and responses. The second component maps HTTP communication into
SPDY data frames. Multiple logical HTTP streams can be multiplexed
using interleaved data frames over a single TCP connection.



2.2 Related Studies

There have been a small number of preliminary studies looking at the per-
formance of SPDY. The first was presented in a Google white paper [2].
By running 25 of the top 100 websites over simulated home networks, this
publication showed significant performance benefits over both HTTP (27-
60%) and HTTPS (39-55%). Whilst this does seem impressive, there are
somewhat conflicting accounts of SPDY’s performance in studies provided
by Akamai [23] and Microsoft [22]. Tests performed by Akamai showed only
a marginal benefit over HTTPS, alongside a decrease in performance when
compared to HTTP. It was found that SPDY, on average, was only about
4.5% faster than HTTPS, and about 3.4% slower than HTTP. Microsoft
offered slightly more positive results, but still did not attain the high levels
previously reported by Google. An Internet Draft by White et al. [32] also
found a mix of results, highlighting that SPDY’s performance would likely
depend on a number of factors, e.g. number of servers, TCP configurations,
network characteristics (specifically, latency and loss). The authors found
an average improvement of 29% over HTTPS. They also reported that such
benefits are not necessarily universal (i.e. they vary for different webpages).
Nevertheless, the Internet Draft does not offer insight into such findings
but rather focuses on coupling SPDY with an increase in the TCP initial
congestion window.

It is difficult to derive a direct conclusion from the above studies as
they offer a wide range of rather conflicting results. Some claim SPDY
outperforms HTTP, whereas others claim the opposite. Consequently, the
only clear conclusion is the SPDY has the potential to have highly variable
performance. As of yet, these studies do not elucidate this observation, i.e.
detailing the reasons behind such variations.

3 Measurement Methodology

3.1 Measurement Toolkit

SPDY is designed to mitigate page load time for end users. We therefore
focus on client-side measurements, for which we have built a toolkit based
on the Chromium browser. This seems a logical choice considering that
both SPDY and Chromium were developed by Google. Chromium also
offers sophisticated logging features that allow us to extract statistics via
automated scripting. We use Chromium 25 (running over Ubuntu Desktop
12.04.2) via the Chrome-HAR-capturer [5] package, which interacts with
Chromium through its remote debugging API. To ensure authenticity, we
maintained all of Chromium’s default settings, apart from disabling DNS
pre-fetching in order to include DNS lookup time in all measurements.


When invoked, our measurement toolkit instructs Chromium to fetch
a particular webpage. Once this is completed, the toolkit extracts detailed
logs in the form of HTTP Archives (HAR) and Wireshark network traces. It
then processes them to calculate metrics of interest. Traditionally, page load
time has been measured by the Document Object Model (DOM) being fully
loaded. However, this is not suitable for our purposes, as it also captures
browser processing time that is strictly HTML-related, e.g. arbitrating the
style hierarchy. Instead, we wish to only measure the time spent performing
network interactions. Thus, we use an alternate metric which we term the
Time on Wire (ToW). This is calculated using Wireshark network traces
as the period between the first request and last response packets, giving us
precise timestamps for the page transmission delay.
Using this toolkit, we employ Chromium in a non-obtrusive manner to
retrieve a number of webpages in a range of different environments. The
collated measurements allow us to explore the performance of SPDY. The
rest of this section details the environments we utilised the measurement
toolkit in.

3.2 Measurement Setups

The measurements are separated into two groups, both using the above
toolkit. First, we perform live tests, probing real-world deployments (e.g.
YouTube) to calculate the performance advantages of organisations cur-
rently using SPDY. Second, we expand on these results using emulated net-
work tests, creating our own controlled SPDY deployment in a local testbed.
The latter allows us to deep-dive into SPDY’s performance in a deterministic
fashion by varying and monitoring the impact of various key factors (namely
network conditions and website infrastructure setup). In both cases, a large
number of samples are taken to ensure statistical significance. Overall, we
have collected over 70,000 probes (12,000 live and 58,000 controlled).

3.2.1 Live Tests

First, we perform live experiments using web sites that have already de-
ployed SPDY in their real infrastructures. To discover these, we have im-
plemented a crawler to probe the top 10k Alexa websites] recording their
individual protocol support. We then select the top 8 Alexa websites that
implement SPDY. We choose only the highest Alexa ranked website from
every distinct online presence and disregard similar sites (facebook.com (#1)
but not fbcdn.net (#202); google.com (#2) but not google.co.in (#12),
google.com.hk (#22), etc.; and so on). The list is shown in Table [I]

The selected websites provide a range of resource sizes, counts, and do-
mains. In terms of their respective delivery infrastructures, we note that all

TAI Alexa ranks henceforth are of April 23"¢ 2013.


Table 1: Live SPDY-enabled Websites

Resources SPDY Av.RTT
Site Count Av. Size (kB) Domains Version IW (ms)
Facebook 20 12.56 4 2 7 92
Google 7 41.29 2 3 7 8
YouTube 50 0.63 4 3 7 8
Blogspot 31 5.03 6 3 7 17
Twitter 7 46.40 3 3 10 158
WordPress 13 7.92 4 2 10 91
imgur 133 .78 58 2 10 8
youm7 270 07 54 2 10 150

appear to use CDNs with the exception of WordPress. We confirm this using
whois as well as other means (e.g. trying to directly access a CloudFlare IP
address with a browser yields an error message from CloudFlare). It seems,
unsurprisingly, that the employed CDN dictates the supported SPDY ver-
sion and the TCP Initial Window (IW) P} We therefore posit that our results

for these sites are representative of the performance for o
the same respective CDN.

her customers of

Using our measurement toolkit, we periodically probe each website from
the Lancaster University campus using HTTP, HTTPS and SPDY. In this

report, we focus on HTTPS as a baseline comparison as,

ike SPDY, it en-

crypts its data. However, where possible, we also include HTTP, considering
that many websites have no interest in securing their connections. In both
cases, when HTTP and HTTPS are used, we avoid bias by forcing Chromium

to pursue the Next Protocol Negotiation (NPN) handsha’
SPDY does. The probes are carried out for each website

ke nonetheless as
in an alternating

sequence of protocols with 2 seconds between each run. For SPDY, we se-
lect the highest non-experimental version that the server supports (listed in
Ta olefIp. Tests were carried out from different sites: Lancaster, Dublin, and
Tokyo. We only discuss the Lancaster set as the other results provide very
similar outcomes. The Lancaster tests ran on weekdays between 12pm and
5pm BST between 20/5/2013 and 23/5/2013. In total, we performed 1.06
million GET requests, with 500 samples taken for each website and protocol

combination.

2Note that increasing the IW size is another closely related component in Google’s
“Make the Web Faster” project. We determined IW by sending self-crafted TCP packets
to the servers. Our program carried out a successful handshake followed by sending a
HTTP GET for a large resource (typically a static image). We then noted the number of

ensuing packets (which we never acknowledged) as the server’s IW.



3.2.2 Emulated Network Tests

The above live experiments provide useful context to the current state of
affairs, but are somewhat limited in what they can tell us. Although the
comparison they provide is fair, it would be difficult to definitely and neu-
trally ascertain SPDY’s performance as it is subject to variations in the
network, and tightly bound to the particular deployment under test: its
characteristics (e.g. web server, SPDY module/proxy) and its status (e.g.
server load). To address these issues, we extend our tests by creating our
own SPDY deployment in an emulated testbed interconnected via a LAN.
This allows us to control the various network parameters to understand how
they impact performance.

Our testbed consists of a client and server setup. The client runs our
measurement toolkit and is connected via 100Mbps Ethernet. We then
emulate various network conditions: the Linux tc utility is used to throttle
bandwidth by shaping traffic with Hierarchy Token Bucket queuing [8], and
NetEm [17] is used (at the server) to specify a deterministic round trip time
(RTT) and packet loss ratio (PLR).

The server runs Ubuntu Server 12.04 with the Apache 2.2.22 web server,
supporting both HTTP and HTTPS. We use Apache’s mod_spdy 0.9.3.3-386
module which implements spdy/3. This is the most advanced SPDY imple-
mentation available, provided by Google’s own SPDY project [I4]. Using
this server, we clone a set of the SPDY websites discovered in the wild;
these are each intended to be representative of a broader class of top Alexa
websites and are as follows:

e Twitter: This is a simple page with only a few (7) resources (average
size 46.4KB). This is comparable to other top Alexa websites such as
Google and Blogspot and their regional versions, Wikipedia, and Soso
(Chinese search engine).

e YouTube: This is a relatively complicated page, with a fair number
(50) of resources (average size 10.63KB). Examples of similar web-
sites include Amazon’s regional websites, AOL, Alibaba (Chinese e-
commerce portal), About.com, and DailyMotion.

e imgur: This is a complicated page, with a large number (133) of im-
ages and flash (average size 11.78KB). Similar websites include QQ
(Chinese messaging website), TaoBao (China’s equivalent to eBay),
The New York Times, CNN, and MSN.

The described setup enables us to have a single server-side SPDY imple-
mentation and a single SPDY-capable web browser, which rules out software
discrepancies (note that we also later use multiple servers). This method
also allows us to control the network characteristics in order to experiment


a HTTP. f Hi
08 5 4 TjuTTPs - - - - r 7 ia
B28] + sepy —— +o
Boa 4 " J 4;
wo "HTTPS - - - - J 15 HTTPS ~~ ~~
 SPDY —— i sPDY ——
0 T T Ta T
0 1500 3000 0 400 800 © 1000 2000 3000 4000 0 1500 3000
ToW (ms) ToW (ms) ToW (ms) ToW (ms)
(a) Facebook (b) Google (c) YouTube (d) Blogspot
1 —
HTTP if HTTP a r |
08 tps - --- “)HTTPS - - - - al f
us 0.6 7 sPbY —— |) sPbY —— 4 4)
Bo44 4 J HTTP J
o24 H | wa J HTTPS - - - - J HTTPS - - - -
“ fF | sPDY —— ‘sPDY ——
0 $< : T T T
© 2000 4000 6000 8000 0 1000 0 5000 10000 0 15000 30000 45000 60000
ToW (ms) ToW (ms) ToW (ms) ToW (ms)
(e) Twitter (£) WordPress (g) imgur (h) youm7

Figure 1: ToW of Live SPDY-enabled Websites

with SPDY under different network conditions. Moreover, server and con-
nection load are also controlled. Using this testbed, we apply the same
methodology as in the live experiments, generating repeated page requests
for the chosen webpages using HTTPS and SPDY. The exact details of the
parameters investigated will be presented in Sections [] and [6]

4 Live Results

We begin by performing experiments with existing deployments of SPDY.
The aim here is not an exhaustive study but, rather, to form a general idea of
the benefits being gained by some of those who have so far adopted SPDY.
To achieve this, each website in Table |l} is probed 500 times to calculate
its ToW. Figure[]] displays the cumulative distribution functions (CDFs) of
these measurements, and Table |2}summarises them. Note that the HTTP
results are not included for websites that redirect such requests to HTTPS.

Confirming our analysis of past studies, the results are not conclusive.
We find no clear winner among the three protocols. Instead, we observe

large performance variations between different websites, as well as between
different samples for the same website. We find that notable improvements
are, indeed, gained in some cases. On average, ToW is reduced by 7% for
Facebook, 4.7% for YouTube, and 9.7% for youm7. The biggest winner is
the Twitter front-page, with an average ToW reduction of 10.6%. This,
however, is not a universal observation. In other cases, improvements are
far more modest; for example, imgur only achieves a meager improvement
of 0.8%. Moreover, we find websites that suffer from their use of SPDY;
an average ToW increase of 6.0% for Blogspot and 15.1% for Wordpress.


Table 2: Gain in ToW for Live SPDY-enabled Websites

Average Gain in ToW
Site (SPDY over HTTPS)
Facebook 7.0%
Google -20.2%
YouTube 4.7%
Blogspot -6.0%
Twitter 10.6%
WordPress -15.1%
imgur 0.8%
youm7 9.7%

Ironically, the biggest sufferer is Google with a 20.2% increase in ToW for
their search homepage. There is certainly no one-size-fits-all operation with
SPDY, as all websites alternate between SPDY and HTTP optimality.

These experiments therefore raise some interesting (yet serious) ques-
tions. From a research perspective, one might ask why these notable varia-
tions occur? From an administrator’s perspective, the next logical question
would then be if SPDY would benefit their deployment? The remainder
of this report now explores these questions using emulated experiments.
Whereas the live experiments limit our control to the client-side, emulated
experiments allow us to dissect all aspects to understand the causes of such
variations.

5 Effect of Network Performance

To understand the reasons behind the variations in performance witnessed
in the wild, we now perform controlled experiments in our testbed. We aim
to examine the effect of different network conditions on the performance gain
of SPDY over HTTPS. We mirror three of the above representative websites
(Twitter, YouTube, imgur) and measure their ToW on a single client, single
server testbed under a variety of network characteristics regarding delay,
bandwidth, and loss.

5.1 Delay

First, we inspect the impact that round trip time (RTT) has on SPDY’s per-
formance. In a real environment, this varies a lot between different requests
due to client locations and path characteristics [18] [10]. To remove any vari-
ance, we fix bandwidth (BW) at 1Mbps and Packet Loss Ratio (PLR) at
0%, whilst changing the RTT between the client and server in a range from
10ms to 490ms. Following this, we perform 20 requests for each website


using each configuration with both SPDY and HTTPS. The results are pre-
sented in Figure [jas the average percentage improvement in ToW of SPDY
over HTTPS.

Twitter
YouTube
imgur

% Reduction in ToW

Figure 2: Effect of Round Trip Time (BW=1Mbps, PLR=0%).

In contrast to the live experiments, we see that SPDY always achieves
better performance than HTTPS in this setup. With low RTTs, these ben-
efits are marginal: requests with RTTs below 150ms achieve under 5% im-
provement on average. These benefits, however, increase dramatically as
the RTT goes up. In the best case (490ms RTT for YouTube), SPDY

beats HTTPS by 21.26%. The resu
fit of SPDY: stream multiplexing. As
expensive for HTTPS to establish se

ts effectively highlight the key bene-
RIT goes up, it becomes increasingly
parate connections for each resource.

Each HTTPS connection costs one round trip on TCP handshaking and

a further two on negotiating SSL se

up. SPDY does this only once (per

server) and hence reduces such large waste by multiplexing streams over a
single connection. By inspecting the HAR logs, we find that SPDY saves
between 66% and 94% of SSL setup time, creating significant gains in high
delay settings.

There is also a notable variation between the different webpages under
test. In the cases of Twitter and YouTube, SPDY’s ability to multiplex is
well exploited by retrieving Twitter’s 7 resources and YouTube’s 50 resources
in parallel. YouTube is by far the greatest beneficiary from SPDY with an
average improvement of 13.81% over HTTPS, whilst Twitter comes second
with 6.87%. The benefits for Twitter are less pronounced because there are
fewer streams that can be multiplexed, therefore reducing the benefits of
SPDY over HTTPS’s maximum of 6 parallel TCP connections (note that
this limit of six is hard coded, based on the amendment to the limit set
by RFC 2616 [I]).

Perhaps more interesting, though, is the fairly steady behaviour exhib-
ited by imgur across all delay values. At first, one would imagine imgur
to benefit greatly from SPDY due to its ability to multiplex imgur’s large

10


number of resources (133). However, performance is very subdued: its over-
all average is 1.32%. To understand this, we inspect the HAR logs to see
what is occuring ‘under the bonnet’. Figure |3] depicts a breakdown of the
HTTPS and SPDY retrieval times for Twitter and imgur at RTT=490ms
and BW=2Mbps. We choose this particular subset of our experiments as
it provides network conditions where both websites achieve equal SPDY-
induced improvement (+15%), and hence provides a fair comparison. The
figure shows the fraction of time spent in the five key stages of page re-
trieval: connect, send, wait, receive and SSL. We notice that the make-up of
these retrievals is remarkably different. As expected, HTTPS spends a lot
of time in the connect and SSL phases, establishing TCP and SSL connec-
tions (respectively). This increases for imgur, which has 19 times as many
resources as Twitter. On the other hand, SPDY greatly reduces the connect
and SSL stages but spends a huge proportion of time in wait. This phase
begins when the browser issues a request for a resource, and ends when an
intial response is received back. The receive phase is time spent receiving
the response data until it is loaded into the browser’s memory. In the case
of SPDY, wait includes not just the network latency between the client and
server but also the time requests are blocked until multiplexed onto the wire.
For imgur, SPDY cuts connect time by 94% but inflates wait time by more
than 9 times. As emulated RTT was the same for both protocols, it ap-
pears that this inflation in wait time is an unfortunate product of SPDY’s
multiplexing, but we are unable to exactly ascertain why multiplexing is cre-
ating this much delay. In other words, SPDY’s savings in establishing new
connections is compromised with multiplexing overhead for highly complex
webpages served over a single connection.

Connect SSSS9 Send @zzzd_ Wait Ss Receive SSL Ea

1 1 imgur
0.8 0.8
3 0.6 3 0.6
3 0.4 3 0.4
é é
0.2 RES 0.2
1) 1)
HTTPS SPDY HTTPS SPDY
Figure 3: Breakdown of HAR Times for Twitter and imgur at RTT=250.
SPDY spends 49% in Wait for Twitter, and 97% for imgur due to its high

resource count.

11


5.2 Bandwidth

Next, we inspect the impact that client bandwidth has on performance.
Once again, this parameter spans a wide range of values across the globe
(4). This time we fix RTT at 150ms and PLR at 0.0%, while setting
client bandwidth to values between 64Kbps and 8Mbps. A first in first out
tail-drop queue of 256 packets length is used to emulate commodity routers
commonly used as residential and public gateways [20] [13]. The results are
presented in Figure

15 T T T T T

Twitter ——-
YouTube J
imgur -----

% Reduction in ToW

64 1024 2048 3072 4096 5120 6144 7168 8192
BW (kbps)

Figure 4: Effect of Bandwidth (RTT=150ms, PLR=0%).

This graph reveals a very different story to that of delay. Confirming the
findings of the live experiments, we see that SPDY does have the potential
to lower performance, and significantly so. This occurs with a clear trend
that favours lower capacities. At 64Kbps, on average, clients witness a 5.75%
improvement over HTTPS, compared to a 22.24% decrease at 8Mbps. Initial
impressions suggest that bandwidth variations have a larger detrimental
impact on SPDY’s performance.

We now have two dimensions of impact — RTT and bandwidth — where
SPDY prefers high delay, low bandwidth (<1Mbps) environments. As pre-
viously discussed, the reason behind SPDY’s sensitivity to RTT is relatively
easy to measure by inspecting the HAR logs. However, its relationship with
bandwidth is rather more complicated. To understand this, we turn our
attention to the network traces. We find that the separation between RTT
and bandwidth is not particularly distinct. This is because HTTPS tends to
operate in a somewhat network-unfriendly manner, creating queueing delays
where bandwidth is low. The bursty use of HTTPS’ parallel connections cre-
ates congestion at the gateway queues, causing upto 3% PLR and inflating

12


RTT by upto 570%] In contrast, SPDY causes negligible packet loss at the
gateway.

The network friendly behaviour of SPDY is particularly interesting as
Google has recently argued for the use of a larger IW for TCP [7]. The
aim of this is to reduce round trips and speed up delivery — an idea which
has been criticised for potentially causing congestion. One question here
is whether or not this is a strategy that is specifically designed to oper-
ate in conjunction with SPDY. To explore this, we run further tests using
IW={3,7, 10,16} and bandwidth fixed at 1Mbps (all other parameters as
above). For HTTPS, it appears that the critics are right: RTT and loss
increase greatly with larger [Ws. In contrast, SPDY achieves much higher
gains when increasing the IW without these negative side effects. It there-
fore seems that Google have a well integrated approach in their “Make the
Web Faster” project. Interestingly, we observe that the key reason that this
increase in RTT and loss adversely affects HTTPS is that it slows down
the connection establishment phase, creating a similar situation to that pre-
sented earlier in Figure[2| Obviously, this congestion also severely damages
window ramping over the HTTPS connections. We can tangibly observe
this by inspecting the client’s TCP window size, which scales far faster with
SPDY than any one of the parallel HTTPS connections; this alone leads to
an average of ©10% more throughput than that of HTTPS.

While this explains SPDY’s superior performance at low bandwidths, it
does not explain its poor performance as capacities increase. As soon as
bandwidth becomes sufficient to avoid the increased congestion caused by
HTTPS, the benefits of SPDY begin to diminish. This is particularly the
case for websites with fewer resources, like Twitter. To understand this,
we breakdown the operations performed by SPDY and HTTPS. Figure
presents the results for YouTube as an example. Again, the two protocols
have very different constitutions. HTTPS spends a large proportion of its
time in the connect phase, setting up TCP and SSL. In contrast, SPDY
spends the bulk of its time in the wait phase. Deep inspection reveals
streams blocking until the connection is free to transmit. In line with our
previous findings, this highlights that SPDY does not always do an effective
job of multiplexing. Whereas, previously, this was caused by the complexity
of the webpage, here it appears that high capacity transmission is also a
challenge. Thus, as bandwidth increases, HTTPS can amortise the costs of
TCP and SSL setup by exploiting the higher raw throughput afforded by
opening parallel TCP sockets. We also observe that this situation occurs
particularly when dealing with larger resources (e.g. images in Twitter), as
window size can be scaled up before each connection ends in HTTPS. In

°We also experimented with different gateway queue sizes. Generally, increasing queue
size caused longer delays and more loss: upto a 920% RTT increase and 5% PLR with a
512 packets queue size, but only 296% maximum RTT inflation and 1% PLR with a queue
of 64 packets.

13


contrast, SPDY appears to struggle to fill TCP’s pipe as the server waits for
new requests for each object from the client. Indeed, the Wireshark traces
show TCP throughput reductions between 2% and 10% in the case of SPDY
due to this problem compared to that of the parallel HTTPS connections.
It would therefore seem that SPDY’s default use of a single TCP connection
might be unwise in circumstances of high bandwidth.

Connect SSSS9 Send @zzzd_ Wait Ss Receive SSL Ea

BR

me Be ee

:
L
HTTPS

Ratio of TOW
geoo
CONROD
T
fi

SPDY

Ratio of ToW
geoo
ONBODOH
1

2, DB, %, W, dy DD, & & %, %, %, %, MH, Y
Ry Sy S25 “03 5, %Os Oo 82, Ve Vy “Os Os, “Rp “Oy “8, “O,
8 ON Se % > S60 Me May ig. My

Bandwidth (Kbps)

Figure 5: HAR Times for different Bandwidth values (YouTube,
RIT=150ms, PLR=0%).

5.3. Packet Loss Ratio

Finally, we inspect the impact of packet loss on SPDY’s performance. We
fix RTT at 150ms and BW at 1Mbps, varying packet loss using the Linux
kernel firewall with a stochastic proportional packet processing rule between
0 and 3%] Figure [6] presents the results.

Immediately, we see that SPDY is far more adversely affected by packet
loss than HTTPS is. This has been anticipated in other work but never
before tested. It is also contrary to what has been reported in the SPDY
white paper [2], which states that SPDY is better able to deal with loss.
The authors suggest because SPDY sends fewer packets, the negative effect
of TCP backoff is mitigated. We find that SPDY does, indeed, send fewer
packets (upto 49% less due to TCP connection reuse). However, SPDY’s
multiplexed connections persist far longer compared to HTTPS. Thus, a lost
packet in a SPDY connection has a more profound setback on the long term
TCP throughput than it would in any of HTTPS’ ephemeral connections,
the vast majority of which do not last beyond the TCP slow start phase

“Packet loss in US mobile networks is reported to be as low as © 0.2% {6] and as high
as 1.9% [16], but is considerably higher in other countries; e.g. 2-3% in many European
countries and > 3% in China, Russia and several South American states [I6]. It is also
quite high for WiFi [25]. We therefore consider 0-3% to be an appropriate parameter
range.

14


% Reduction in ToW

Twitter

-100 | YouTube

imgur,

0 0.5 1 15 2 2.5 3
Packet Loss Ratio (%)

Figure 6: Effect of Packet Loss (RTT=150ms, BW=1Mbps).

[27]. Furthermore, packet loss in SPDY affects all following requests and
responses that are multiplexed over the same TCP connection. In contrast,
a packet loss in one of the parallel HTTPS connections would not affect
the other connections, neither concurrent nor subsequent (assuming HTTP
pipelining is not used, which is commonly the case). In essence, HTTPS
‘spreads the risk’ across multiple TCP connections. On average, we found
that SPDY’s throughput is affected by packet loss up to 7 times more than
HTTPS (all experiments were performed using the default Linux CUBIC
congestion avoidance algorithm).

It is also important to note that the probability of packet loss is higher
in SPDY. According to [12], the probability of experiencing loss increases in
proportion to the position of the packet in a burst chain. Hence, the chance
of experiencing a packet tail drop is much higher for longer lived connections
such as SPDY’s. Thus, not only does SPDY react badly to packet loss, the
chance of it experiencing loss is also higher. This is effectively highlighted
in Figure |6} imgur, which has the longest transfer time (by far), exhibits
extremely poor performance under packet loss.

Finally, these results indicate that SPDY may not perform that well in
mobile settings, one of its key target environments [31]. Whilst both SPDY’s

high delay and low bandwidth support is desirable in this environment, the
benefits can be undone by relatively low levels of packet loss (e.g. 0.5%).

6 Effect of Infrastructural Decisions

The previous section has investigated the performance of SPDY under differ-
ent network conditions between a single client and server. However, our orig-
inal crawling of the Alexa Top 10k highlighted a tendency for providers to
implement a practice known as domain sharding. This is the process of dis-
tributing page resources across multiple domains (servers), allowing browsers
to open more parallel connections to download page resources. Figure

15


presents a CDF of the number of shards we discovered. We find that apart
from front-less websites (such as media.tumblr.com and akamaihd.net), all
websites employ some degree of domain sharding. Here, we choose to deep
dive into the practice of domain sharding to understand the implications of
this infrastructural design choice on SPDY.

0 10 20 30 40 50 60 70 80 90 100
Number of Domains

Figure 7: Number of Alexa Websites Resource Domains

6.1 Number of Shards

To inspect the impact of sharding, we recreate the earlier experimental setup
but mirror the webpages across multiple servers, as occurs in real setups.
We consider 7 shards, i.e. servers, an appropiate upper limit here as our
measurements find that 70 of the top 100 Alexa websites have 7 or fewer
shards. Each shard is configured as in Section 3.2.2] We then distribute the
webpage resources across these servers. We perform retrievals using con-
figurations between 1 and 7 shards, after adapting the HTML to reference
shards in a round robin fashion. The client is configured with 1Mbps band-
width, 150ms RTT and 0% PLR. Figure [8] presents the results of 100 runs
at each configuration.

We first note that sharding distinctly decreases SPDY’s gain for YouTube
and imgur. As the number of shards increases, so does the maximum number
of parallel HTTPS connections. SPDY, too, is forced into creating multiple
parallel TCP connections (one to each server). Hence, both protocols are al-
lowed to capitalise on increased parallelism. However, the benefits achieved
by HTTPS outweigh those of SPDY as the former gains 6 new TCP con-
nections per shard, a large performance boost that, in essence, offers SPDY-
like multiplexing. This, therefore, reduces the overall improvement offered
by SPDY. Another ramification of sharding evident from the examples of
YouTube and imgur, is that as SPDY opens more connections, it multiplexes
fewer streams per connection. This diminishes the returns of multiplexing
which is SPDY’s main competitive advantage over HTTPS. This suggests,

16


Twitter
YouTube
imgur

% Reduction in ToW

Number of Shards

Figure 8: Effect of the Number of Shards

based on our findings in Section [5.2] that increasing the servers’ IW would
give SPDY an advantage and the potential to tip the balance in its favour.

The case of Twitter provides a different insight. Here, fairly steady
results are achieved across all sharding levels. SPDY gains marginal im-
provements over HTTPS by reducing the number of round trips, which is
dictated by the number of resources in a page. For such a page with only 7
resources, SPDY saves between one and two round trips at 1 shard (depend-
ing on whether all resources were requested together or at different times as
the page is rendered). With more shards, the number of round trips that
SPDY potentially saves is reduced to only one, if any, due to its reduced abil-
ity to multiplex. Whereas, in the case of HTTPS, more shards means fewer
resources (and hence fewer parallel connections) per shard. This has the
effect of gradually decreasing HTTPS’ parallelism as the number of shards
increase, hence allowing SPDY to continue to retain an edge.

In summary, we deduce that SPDY loses its performance gains as a
website is sharded more. However, these negative results are not ubiquitous
and vary remarkably depending on the number of page resources. This
raises a few questions about SPDY deployment. Are the benefits enough for
designers and admins to restructure their websites to reduce sharding? What
about third party resources that cannot be consolidated, e.g. ads and social
media widgets? Can SPDY be redesigned to multiplex across domains? Is
proxy deployment [29] rewarding and feasible as a temporary solution? The
success of SPDY (and thereupon HTTP/2.0) is likely to be dependent on
the answers to precisely these questions.

6.2. Number of Multiplexed Streams

So far, we have seen that sharding can create a significant challenge to
SPDY’s performance by forcing it into HTTP-like behaviour and by that
limiting its ability to perform stream multiplexing. To further inspect this,
we now directly study the impact of this multiplexing by artificially changing

17


the maximum number of streams allowed per connection. This allows us to
control exactly the degree of multiplexing afforded by SPDY. We vary this
value from 1 to 100 (which is the default in Apache, as recommended by
the SPDY draft [3]) whilst mirroring the three websites on a single server.
We perform these retrievals for a variety of RTTs. We choose to vary RTT
because of the discovery that many of the bandwidth impacts are actually
products of the inflated RTTs caused by queuing. Bandwidth is fixed at
1Mbps and PLR at 0%.

In Figure [9] the average improvement in ToW (over HTTPS) for each
multiplexing degree is displayed as a trend line, whilst the ToW reduction
over different RTT values is shown as a heatmap to elicit more generalisable
results. In all cases, SPDY’s multiplexing has the potential to improve the
ToW. For YouTube and imgur, we see a direct relationship between these
benefits and the level of multiplexing afforded by SPDY. Here, these benefits
plateau at 10 streams for YouTube and at 30 for imgur. In contrast, the
results for Twitter remain relatively steady for all levels of multiplexing.

To explore the different results for each page, we inspect the nature of
their resources, as well as SPDY’s recorded behaviour when accessing them.
We confirm that these results are a product of the complexity of the web-
pages in terms of their resources. Twitter benefits little from increasing the
multiplexing degree, as it only possesses 7 resources, i.e. no further benefits
can be achieved when multiplexing beyond this level. The inverse case is
found with YouTube (50 resources) and imgur (133 resources), which clearly
can exploit multiplexing levels beyond 7 streams. Preventing this from hap-
pening has dire ramifications: when allowing SPDY to multiplex fewer than
6 streams for YouTube and imgur, it performs worse then HTTPS. This
therefore confirms the negative impact that sharding will have on SPDY’s
deployment, where multiplexing capabilities could be severely undermined.
We found these observations to be true for even more complicated websites,
e.g. the New York Times website (148 resources).

To better understand the relationship between performance and page
complexity, we perform regression analysis to look at the multiplexing level
(m) required to outperform HTTPS for a website with a given number of
resources (r). This is done for all websites under test in addition to three
other websites we experimented with. We find that m = r/4, with a very
strong fit (R? = 0.98537, p-value= 8.0684 x 10~°). This is not a robust
model and is not intended to be so; it effectively highlights the impact that
page type will have on SPDY’s performance. Another interesting point here
is that intuition would perhaps lead towards a 1/6 relationship, due to the
maximum number of parallel HTTPS connections. Instead, m is found to
be of greater value. We are not able to pinpoint the reasons behind this,
but it could be attributed to SPDY’s multiplexing overheads diagnosed in
section [5]

18


4
400 12
=
10 2
ge 300 £
= 200 6 3
@
48
100
2
0 0
10 20 30 40 50 60 70 80 90 100
Number of Multiplexed Streams
(a) Twitter
500 25
400 20
2
ge 300 IS
E i
= 200 10 3
2
&
100 5
0 0
10 20 30 40 50 60 70 80 90 100
Number of Multiplexed Streams
(b) YouTube
500 10
8
400
‘8
@ 300 £
é ‘ 5
E m0 23
2
os
100
2
0 “4
10 20 30 40 50 60 70 80 90 100

Number of Multiplexed Streams

(c) imgur

Figure 9: Effect of the Number of Multiplexed Streams per SPDY Connec-
tion over Varying RTTs.

7 Conclusions & Future Work

SPDY provides a low-cost upgrade of HTTP, aiming to reduce page load
times leading to improved user experience. To do this, it introduces a vari-

19


ety of new features, including stream multiplexing and header compression.
Currently, the behaviour and performance of SPDY are quite poorly un-
derstood, exacerbated by the often conflicting results reported by various
early stage studies. Our own live experiments confirmed these observations,
highlighting SPDY’s ability to both decrease and increase page load times.

We therefore turned our efforts to identifying the conditions under which
SPDY thrives. We found that SPDY offers maximum improvement when
operating in challenged environments, i.e. low bandwidth and high delay.
We concluded that stream multiplexing is at the heart of SPDY’s perfor-
mance. This feature allows it to minimise the number of round trips required
to fetch resources. It also facilitates more disciplined congestion control,
which allows SPDY to outshine HTTP on low bandwidth links and pro-
motes further network enhancements such as increasing TCP’s IW. On the
other hand, SPDY’s multiplexed connections last much longer than HTTP’s,
which makes SPDY more susceptible to loss and the subsequent issues with
TCP backoff.

We then investigated the impact of infrastructural decisions on SPDY’s
performance, namely the prevalent practice of domain sharding. We ob-
served that SPDY’s benefits are reduced in sharded environments where
SPDY is prevented from maximising on multiplexing. We predict this could
have palpable implications on website design and deployment strategies. Fi-
nally, we observed throughout our experiments that page type has huge in-
fluence on SPDY’s performance: SPDY favours pages with more and larger

resources, as opposed to pages with a very large number of small resources
which induces perceptible multiplexing overheads.

So far, we have investigated only a subset of SPDY’s overall parameter
space and, thus, our future work intends to focus on expanding these exper-
iments. This includes alternate network configurations, but also extends to
inspecting other SPDY features (e.g. Server Push and Hint). A particularly
important aspect of our future work is to formulate a better understanding
of SPDY’s behaviour in relation to the different page characteristics, which
we have discovered to have a profound impact on performance. Finally, this
work should feed into the wider discussion regarding HTTP/2.0, and the
future of the web.

8 Acknowledgments

This work was partly supported by the NERC EVOp (NE/I002200/1) and
EPSRC IU-ATC (EP/J016748/1) projects. We thank Dr. Rajiv Ramdhany
for access to testbed resources, and Prof. Gordon §S. Blair for his valuable
feedback.

20


References

10

11

12

13

HTTP Archive. http: //httparchive.org/

Spdy: An experimental protocol for a faster web. http://www.
chromium. org/spdy/spdy-whitepaper|

M. Belshe and R. Peon. SPDY Protocol. http://tools.ietf.org/
html/draft-mbelshe-httpbis-spdy-00, Feb 2012. IETF Network

Working Group.

D. Belson. Akamai state of the internet report. 5(4). [nttp://www.
akamai.com/stateoftheinternet, 2012.

A. Cardaci. chrome-har-capturer. https: //github.com/cyrus-and/

Y.-C. Chen, D. Towsley, E. M. Nahum, R. J. Gibbens, and Y.-s. Lim.
Characterizing 4G and 3G networks: Supporting mobility with multi-
oath TCP. Technical report, UMass Amherst Technical Report: UM-
CS-2012-022, 2012.

J. Chu, N. Dukkipati, Y. Cheng, and M. Mathis. Increasing TCP’s
nitial Window. RFC 6928 (Experimental), Apr 2013.

{. Devera. Hierachical token bucket theory. http://luxik.cdi.cz/
~devik/qos/htb/manual/theory .htm, May 2002.

{. Dischinger, A. Haeberlen, K. P. Gummadi, and S. Saroiu. Charac-
erizing residential broadband networks. In Proc. IMC, pages 43-56.
ACM, 2007.

Y. Elkhatib. Monitoring, Analysing and Predicting Network Perfor-
mance in Grids. PhD thesis, Lancaster University, Lancaster, UK,
September 2011.

R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach,
and T. Berners-Lee. Hypertext Transfer Protocol - HTTP/1.1. RFC
2616 (Draft Standard), Jun 1999. Updated by RFCs 2817, 5785, 6266,
6585.

T. Flach, N. Dukkipati, A. Terzis, B. Raghavan, N. Cardwell, Y. Cheng,
A. Jain, S. Hao, E. Katz-Bassett, and R. Govindan. Reducing web
latency: the virtue of gentle aggression. In Proc. SIGCOMM, 2013.

J. Gettys and K. Nichols. Bufferbloat: Dark buffers in the internet.
Queue, 9(11):40:40-40:54, Nov 2011.

21


14

15

16

17

18

19

20

21

22

23

24

25

26

27

Google SPDY project. mod-spdy: Apache SPDY module.
code. google. com/p/mod-spdy/

H. W. Group. Ticket #131: increase connection limit. http://trac.
tools. ietf.org/wg/httpbis/trac/ticket/131| Sep 2008.

M. V. Heikkinen and A. W. Berger. Comparison of user traffic charac-
teristics on mobile-access versus fixed-access networks. In Proc. PAM,
pages 32-41. Springer, 2012.

S. Hemminger. Network emulation with NetEm. In Proc. of Linux
Conf. Australia, pages 18-23. Citeseer, 2005.

S. Kaune, K. Pussep, C. Leng, A. Kovacevic, G. Tyson, and R. Stein-
metz. Modelling the internet delay space based on geographical loca-
ions. In Proc. Conf. Parallel, Distributed and Network-based Process-
ing, pages 301-310, Feb 2009.

R. Kohavi and R. Longbotham. Online experiments: Lessons learned.
IEEE Computer Magazine, 40(9):103-105, 2007.

F. Li, M. Li, R. Lu, H. Wu, M. Claypool, and R. Kinicki. Measur-
ing queue capacities of IEEE 802.11 wireless access points. In Proc.
BroadNets, pages 846-853, Sep 2007.

F. F.-H. Nah. A study on tolerable waiting time: how long are web users
willing to wait? Behaviour & Information Technology, 23(3):153-163,
2004.

J. Padhye and H. F. Nielsen. A comparison of SPDY and HTTP per-
formance. Microsoft Technical Report MSR-TR-2012-102, 2012.

G. Podjarny. Not as spdy as you thought. http://www. guypo.com/
technical/not-as-spdy-as-you-thought/, 2012.

C. Severance. JavaScript: Designing a language in 10 days. [EEE
Computer Magazine, 45(2):7-8, 2012.

A. Sheth, S. Nedevschi, R. Patra, S. Surana, E. Brewer, and L. Sub-
ramanian. Packet loss characterization in WiFi-based long distance
networks. In Proc. INFOCOM, pages 312-320, 2007.

Y. X. Skadberg and J. R. Kimmel. Visitors’ flow experience while brows-
ing a web site: its measurement, contributing factors and consequences.
Computers in human behavior, 20(3):403-422, 2004.

P. Sun, M. Yu, M. J. Freedman, and J. Rexford. Identifying perfor-
mance bottlenecks in CDNs through TCP-level monitoring. In SIG-
COMM workshop on Measurements Up the Stack, pages 49-54. ACM,
2011.

22


[28] S. Sundaresan, W. de Donato, N. Feamster, R. Teixeira, S. Crawford,
and A. Pescapé. Broadband internet performance: a view from the
gateway. In Proc. SIGCOMM, pages 134-145. ACM, 2011.

[29] B. Thomas, R. Jurdak, and I. Atkinson. SPDYing up the web. Com-
mun. of ACM, 55(12):64-73, Dec 2012.

[30] R. Trace, A. Foresti, S. Singhal, O. Mazahir, H. F. Nielsen, B. Raymor,

R. Rao, and G. Montenegro. HTTP Speed+Mobility. http://tools.
ietf.org/htm1/draft-montenegro-httpbis-speed-mobility-02,
Jun 2012. IETF Network Working Group.

[31] M. Welsh, B. Greenstein, and M. Piatek. SPDY Performance on Mo-

vile Networks. https://developers.google.com/speed/articles/
spdy-for-mobile, Apr 2012. Google ‘Make the Web Faster’ project.

[32] G. White, J. Mule, and D. Rice. Analysis of SPDY

and TCP TInitewnd. http://tools.ietf.org/html/
draft-white-httpbis-spdy-analysis-00, Jul 2012. IETF Network
Working Group.

23
